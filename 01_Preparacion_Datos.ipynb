{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darwinagudeloh/FDL_2024-2_UDEA/blob/main/01_Preparacion_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "hz_6sBeQWpjF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de archivos en el repositorio\n",
        "base_url = \"https://raw.githubusercontent.com/darwinagudeloh/FDL_2024-2_UDEA/refs/heads/main/\"\n",
        "files = [\"punto1.csv\", \"punto2.csv\", \"punto3.csv\", \"punto4.csv\", \"punto5.csv\", \"punto6.csv\"]"
      ],
      "metadata": {
        "id": "YMt-aLlcWw9F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario para almacenar los DataFrames de cada ubicación\n",
        "data_dict = {}\n",
        "\n",
        "for file in files:\n",
        "    # Construir la URL de cada archivo\n",
        "    file_url = base_url + file\n",
        "\n",
        "    # Descargar el archivo desde GitHub\n",
        "    response = requests.get(file_url)\n",
        "    if response.status_code == 200:\n",
        "        # Leer el contenido del archivo en un DataFrame\n",
        "        df = pd.read_csv(StringIO(response.text), skiprows=9)  # skiprows=9 para omitir las primeras líneas del encabezado\n",
        "\n",
        "        # Extraer el nombre del archivo sin extensión para usar como identificador\n",
        "        location = file.split(\".\")[0]\n",
        "\n",
        "        # Renombrar las columnas para que sean consistentes\n",
        "        df = df.rename(columns={\"YEAR\": \"year\", \"MO\": \"month\", \"DY\": \"day\", \"WS10M_MAX\": f\"WS10M_MAX_{location}\"})\n",
        "\n",
        "        # Combinar las columnas de año, mes y día en una sola columna de fecha\n",
        "        df[\"Date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
        "\n",
        "        # Seleccionar solo las columnas necesarias\n",
        "        df = df[[\"Date\", f\"WS10M_MAX_{location}\"]]\n",
        "\n",
        "        # Agregar el DataFrame al diccionario\n",
        "        data_dict[location] = df\n",
        "        print(f\"{file} descargado y procesado con éxito.\")\n",
        "    else:\n",
        "        print(f\"Error al descargar {file}. Código de estado: {response.status_code}\")"
      ],
      "metadata": {
        "id": "BipGKqViX7vK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8f1f06-dcf9-48f3-c87f-203b57f13529"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punto1.csv descargado y procesado con éxito.\n",
            "punto2.csv descargado y procesado con éxito.\n",
            "punto3.csv descargado y procesado con éxito.\n",
            "punto4.csv descargado y procesado con éxito.\n",
            "punto5.csv descargado y procesado con éxito.\n",
            "punto6.csv descargado y procesado con éxito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combinar los DataFrames de todas las ubicaciones en uno solo\n",
        "combined_data = data_dict[list(data_dict.keys())[0]]  # Inicializar con el primer DataFrame\n",
        "for location, df in data_dict.items():\n",
        "    if location != list(data_dict.keys())[0]:  # Saltar el primer DataFrame ya incluido\n",
        "        combined_data = pd.merge(combined_data, df, on=\"Date\", how=\"outer\")\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame combinado\n",
        "print(combined_data.head())"
      ],
      "metadata": {
        "id": "_2mLTub7X_8Q",
        "outputId": "b165767b-6618-4b74-8c30-8eec68f5ac55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date  WS10M_MAX_punto1  WS10M_MAX_punto2  WS10M_MAX_punto3  \\\n",
            "0 2014-01-01              1.93              1.35              1.01   \n",
            "1 2014-01-02              2.03              1.55              1.45   \n",
            "2 2014-01-03              1.29              1.49              1.30   \n",
            "3 2014-01-04              2.19              1.28              1.30   \n",
            "4 2014-01-05              1.20              1.02              1.29   \n",
            "\n",
            "   WS10M_MAX_punto4  WS10M_MAX_punto5  WS10M_MAX_punto6  \n",
            "0              2.17              2.55              1.41  \n",
            "1              2.39              3.48              1.06  \n",
            "2              1.78              2.66              1.50  \n",
            "3              1.78              2.64              1.96  \n",
            "4              2.39              3.58              1.46  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guarda el DataFrame combinado en Google Drive\n",
        "#combined_data.to_csv('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/dataset/combined_wind_data.csv', index=False)"
      ],
      "metadata": {
        "id": "a3kphdQKYDFO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPGi9AHCYTgn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}