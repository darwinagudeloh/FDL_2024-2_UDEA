{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darwinagudeloh/FDL_2024-2_UDEA/blob/main/03_Preprocesamiento_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías\n",
        "import requests\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib"
      ],
      "metadata": {
        "id": "DywF-xR0wlKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo CSV desde GitHub\n",
        "file_path = \"https://raw.githubusercontent.com/JulianaCarvajal/Proyecto_Deep_Learning/main/combined_wind_data.csv\"\n",
        "\n",
        "# Descargar el archivo desde GitHub\n",
        "response = requests.get(file_path)\n",
        "if response.status_code == 200:\n",
        "    # Leer el contenido del archivo en un DataFrame\n",
        "    data = pd.read_csv(StringIO(response.text))\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "L_-vkMZ5wuY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna 'Date' a tipo datetime\n",
        "data['Date'] = pd.to_datetime(data['Date'])"
      ],
      "metadata": {
        "id": "uhU32Ggxd_Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización de las Variables\n",
        "# Seleccionar columnas numéricas para normalización (excluir 'Date')\n",
        "columns_to_normalize = [col for col in data.columns if 'WS10M_MAX' in col]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])"
      ],
      "metadata": {
        "id": "MDruUfyzwvKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para Crear Secuencias con Horizontes\n",
        "sequence_length = 30  # Ventana de 30 días\n",
        "\n",
        "def create_sequences_with_horizon(data, seq_length, horizon):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length - horizon):\n",
        "        # Entrada: Todas las columnas excepto la columna objetivo\n",
        "        X.append(data.iloc[i:i + seq_length, :].values)  # Incluye todas las columnas\n",
        "        # Salida: Solo la columna objetivo desplazada por el horizonte\n",
        "        y.append(data.iloc[i + seq_length + horizon]['WS10M_MAX_punto6'])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "HrZxWqNFxJEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear Secuencias para Horizonte de 7 Días\n",
        "horizon_7_days = 7\n",
        "\n",
        "X_7, y_7 = create_sequences_with_horizon(data[columns_to_normalize], sequence_length, horizon_7_days)\n",
        "\n",
        "# División en Entrenamiento, Validación y Prueba\n",
        "train_size_7 = int(0.7 * len(X_7))\n",
        "val_size_7 = int(0.15 * len(X_7))\n",
        "\n",
        "X_train_7, y_train_7 = X_7[:train_size_7], y_7[:train_size_7]\n",
        "X_val_7, y_val_7 = X_7[train_size_7:train_size_7 + val_size_7], y_7[train_size_7:train_size_7 + val_size_7]\n",
        "X_test_7, y_test_7 = X_7[train_size_7 + val_size_7:], y_7[train_size_7 + val_size_7:]"
      ],
      "metadata": {
        "id": "_-JkZOPGfs0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear Secuencias para Horizonte de 15 Días\n",
        "horizon_15_days = 15\n",
        "\n",
        "X_15, y_15 = create_sequences_with_horizon(data[columns_to_normalize], sequence_length, horizon_15_days)\n",
        "\n",
        "# División en Entrenamiento, Validación y Prueba\n",
        "train_size_15 = int(0.7 * len(X_15))\n",
        "val_size_15 = int(0.15 * len(X_15))\n",
        "\n",
        "X_train_15, y_train_15 = X_15[:train_size_15], y_15[:train_size_15]\n",
        "X_val_15, y_val_15 = X_15[train_size_15:train_size_15 + val_size_15], y_15[train_size_15:train_size_15 + val_size_15]\n",
        "X_test_15, y_test_15 = X_15[train_size_15 + val_size_15:], y_15[train_size_15 + val_size_15:]"
      ],
      "metadata": {
        "id": "6c6YfH66xVlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Guardar los Datos Procesados\n",
        "# # Guardar conjuntos de datos\n",
        "# # Guardar conjuntos para horizonte de 7 días\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/X_train_7.npy', X_train_7)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/y_train_7.npy', y_train_7)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/X_val_7.npy', X_val_7)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/y_val_7.npy', y_val_7)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/X_test_7.npy', X_test_7)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/y_test_7.npy', y_test_7)\n",
        "\n",
        "# # Guardar conjuntos para horizonte de 15 días\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/X_train_15.npy', X_train_15)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/y_train_15.npy', y_train_15)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/X_val_15.npy', X_val_15)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/y_val_15.npy', y_val_15)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/X_test_15.npy', X_test_15)\n",
        "# np.save('/content/drive/MyDrive/Fundamentos de Deep Learning/Proyecto/y_test_15.npy', y_test_15)"
      ],
      "metadata": {
        "id": "P8KKIxGoxZLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6k0WnebhAUMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}